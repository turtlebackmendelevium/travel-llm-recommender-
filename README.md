**ğŸ§  Travel LLM Recommender
A smart, modular recommendation system that explores and compares three major techniques for travel recommendations using Large Language Models (LLMs):

âœ… Prompt Engineering

âœ… Fine-Tuning a T5 Transformer

âš™ï¸ Retrieval-Augmented Generation (RAG) (in progress)

ğŸš§ This is a work-in-progress project intentionally structured to reflect real-world iterative development. Recruiters: See below for whatâ€™s complete and how each part demonstrates relevant technical skill.

**ğŸ” Project Goal
Build a smart travel assistant that recommends destinations using natural language inputs and integrates:

LLMs via Hugging Face

Custom dataset curation (TripAdvisor + European destination data)

Vector search with FAISS

Text embeddings via Sentence Transformers

Evaluation and optimization across LLM techniques

**âœ… Completed Components
1. ğŸ”§ Prompt Engineering
Developed a structured prompt template for travel recommendations

Integrated LLM API (DeepSeek) for iteration

Demonstrated impact of prompt structure on model outputs

2. ğŸ§ª Fine-Tuning with Hugging Face Transformers
Used a cleaned and formatted JSONL dataset of travel queries

Fine-tuned a T5 model using Hugging Faceâ€™s Trainer API

Ran training locally using PyTorch with checkpoints saved and reused

Evaluated model output to prevent overfitting on input sequences

Final model saved at: finetune/output/final-model

3. ğŸ“ Data Preprocessing & EDA
Merged multiple datasets (TripAdvisor, 2023 reviews, European destinations)

Cleaned CSVs, handled encoding issues, removed redundancy

Used pandas, numpy, and langchainâ€™s document loaders for formatting

Explored and visualized travel patterns to better guide model behavior

**ğŸš§ In Progress
4. ğŸ”„ RAG (Retrieval-Augmented Generation)
Set up LangChain pipeline using:

RecursiveCharacterTextSplitter

HuggingFaceEmbeddings (all-MiniLM-L6-v2)

FAISS for similarity search

Current status: Indexing is taking unusually long due to large corpus size

Next Steps:

Monitor and optimize document splitting

Finalize vectorstore saving/loading

Connect RAG to inference script for hybrid QA generation

**ğŸ› ï¸ Tech Stack
Tool	Purpose
ğŸ Python	Core programming
ğŸ§  Hugging Face Transformers	LLMs, tokenizers, fine-tuning
ğŸ”— LangChain	RAG + Embedding pipeline
ğŸ§® FAISS	Vector store for semantic search
ğŸ”¤ Sentence Transformers	all-MiniLM-L6-v2 for embedding
âš™ï¸ PyTorch	Model training backend
ğŸ“Š Pandas / NumPy	Data prep and transformation
ğŸ“ JSONL / CSV	Data formats

travel-llm-recommender/
â”‚
â”œâ”€â”€ finetune/
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ dataset.jsonl
â”‚   â””â”€â”€ output/
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ build_index.py      â† [Indexing logic]
â”‚   â”œâ”€â”€ querry_rag.py       â† [Querying interface]
â”‚
â”œâ”€â”€ datasets_raw/           â† [CSV source files]
â”‚
â””â”€â”€ README.md               â† [You're here]

**âœï¸ What I Learned
Fine-tuning a transformer model with custom data

Data formatting best practices for NLP

Comparative analysis of LLM techniques (prompting vs fine-tuning vs RAG)

Troubleshooting LangChain and Hugging Face integration

Managing real-world dataset inconsistency (encoding, structure)

**ğŸ“Œ Why This Project Matters
This project isn't just about the end resultâ€”it's a demonstration of:

ğŸ” Deep understanding of LLM internals

ğŸ§± Layered architecture (modular components)

ğŸ§  Ability to evaluate and iterate between techniques

ğŸ§© Clear version control and extensibility

Even though RAG is still being finalized, the depth of experimentation, full fine-tuning pipeline, and understanding of embedding-driven retrieval clearly show readiness for applied AI/ML roles.

**ğŸ”œ Next Steps
Complete FAISS indexing and connect it to RAG query script

Add Streamlit UI for demo

Implement unit tests for each module

Optional: Dockerize and deploy inference API


ğŸ’» VS Code	Dev environment

